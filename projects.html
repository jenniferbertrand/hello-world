<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jennifer Bertrand | Research Projects</title>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            line-height: 1.6;
        }
        header, footer {
            text-align: center;
            padding: 20px;
        }
    .content {
        max-width: 900px;
        margin: auto;
        padding: 20px;
    }
    .project {
        margin-bottom: 30px;
    }
    .project img {
        display: block;
        margin: 20px auto;
        max-width: 70%;
        height: auto;
    }
    </style>
</head>
<body>
    <header>
        <h1>Jennifer Bertrand</h1>
        <nav>
            <a href="index.html">Home</a> | 
            <a href="contact.html">Contact</a>
        </nav>
        <p>Post-doctoral Researcher focused on Digital Health, Human Movement + Activity Tracking, and Tech-Driven Patient-Centered Health Solutions </p>
    </header>

    <div class="content">
        <h2>Current Research</h2>
        
        <h3>Remote Motion Capture + Wearables for Physical Assessments</h3>
        <p><strong>Overview</strong>: This project focuses on exploring how motion capture and wearable sensor technologies can be applied remotely to assess physical function in patients with chronic conditions, aiming to improve accessibility through telehealth solutions.</p>

        <h2>Past Work</h2>

        <div class="project">
            <img src="images/HansenETComponents_JB.png" alt="Eye-tracking Image">
            <div class="project-text">
                <h3>Remote Eye-tracking for Behavioral Research</h3>
                <p><strong>Overview</strong>: In response to the pandemic, we adapted our behavioral research to fully remote settings by leveraging webcam-based eye-tracking technology. This innovation allowed us to conduct complex visual attention studies without in-person lab access. We tested the limits of remote methods and successfully captured decision-making processes, demonstrating that remote eye-tracking can produce reliable data across a wide range of participants in diverse home environments.</p>
                <p><strong>Key Contributions</strong>: Pioneered webcam-based eye-tracking for fully remote studies. Validated the technology's ability to capture decision-making data remotely. Enabled broader and more inclusive participant engagement during the pandemic.</p>
                <p><strong>Methods</strong>: Webcam-based eye-tracking, remote behavioral analysis, online data collection + experimentation.</p>
            </div>
        </div>

        <h3>EEG-based Cognitive Neuroscience Research</h3>
        <p><strong>Overview</strong>: This project explored the neural correlates of  and perception using EEG. The research uncovered brain activity patterns related to the cognitive processes underlying visual perception.</p>
        <p><strong>Key Contributions</strong>: Investigated the brain rhythms involved in visual perception and cognition. Programatically processed complex, multimodal timeseries data.</p>
        <p><strong>Methods</strong>: EEG data collection, neural signal processing, cognitive task-based experiments.</p>

        <h3>Cursor Tracking for Behavioral Analysis</h3>
        <p><strong>Overview</strong>: This project investigated human behavior through remote cursor tracking techniques, tracking and analyzing decision-making patterns in real-time through participants' online interactions.</p>
        <p><strong>Key Contributions</strong>: Developed web-based tools for remotely tracking and analyzing user behavior. Analyzing decision-making in digital interactions.</p>
        <p><strong>Methods</strong>: Remote cursor tracking software, spatiotemporal data analysis, online experimentation focused on decision-making tasks.</p>

        <h3>Eye + Cursor Tracking and Human-Computer Interaction</h3>
        <p><strong>Overview</strong>: This project explored how humans interact with digital interfaces, particularly in the dynamic interplay of eye movements and the mouse cursor. </p>
        <p><strong>Key Contributions</strong>: Conducted experiments on eye and cursor patterns in digital user interactions.</p>
        <p><strong>Methods</strong>: Eye-tracking for human-computer interaction, user interactions, behavioral data collection.</p>

        <h3>Remote Experimentation During the Pandemic</h3>
        <p><strong>Overview</strong>: This project transitioned lab-based research into remote platforms, allowing us to conduct complex behavioral and cognitive experiments entirely online during the COVID-19 pandemic.</p>
        <p><strong>Key Contributions</strong>: Developed remote experimentation tools, enabling us to engage broader participant populations during the pandemic.</p>
        <p><strong>Methods</strong>: Remote experimentation tools, webcam-based behavioral tracking, online data collection.</p>

    </div>

    <footer>
        <p>&copy; 2024 Jennifer Bertrand</p>
    </footer>
</body>
</html>
